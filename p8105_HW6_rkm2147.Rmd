---
title: "p8105_HW6_rkm2147"
author: "Ronae McLin"
date: "12/7/2020"
output: github_document
---


```{r setup, include=FALSE}
library(tidyverse)
library(viridis)
knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

```{r load_libraries}
library(tidyverse)
library(modelr)
library(p8105.datasets)
library(mgcv)
```

### Problem 1

```{r}
homicide_df = 
  read_csv("./large_data/homicide-data.csv", na = c("", "NA", "Unknown")) %>% 
  mutate(
    city_state = str_c(city, state, sep = ", "),
    victim_age = as.numeric(victim_age),
    resolution = case_when(
      disposition == "Closed without arrest" ~ 0,
      disposition == "Open/No arrest"        ~ 0,
      disposition == "Closed by arrest"      ~ 1)
  ) %>% 
  filter(
    victim_race %in% c("White", "Black"),
    city_state != "Tulsa, AL") %>% 
  select(city_state, resolution, victim_age, victim_race, victim_sex)
```


Start with one city.

```{r}
baltimore_df =
  homicide_df %>% 
  filter(city_state == "Baltimore, MD")
glm(resolution ~ victim_age + victim_race + victim_sex, 
    data = baltimore_df,
    family = binomial()) %>% 
  broom::tidy() %>% 
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(term, OR, starts_with("CI")) %>% 
  knitr::kable(digits = 3)
```


Try this across cities.

```{r}
models_results_df = 
  homicide_df %>% 
  nest(data = -city_state) %>% 
  mutate(
    models = 
      map(.x = data, ~glm(resolution ~ victim_age + victim_race + victim_sex, data = .x, family = binomial())),
    results = map(models, broom::tidy)
  ) %>% 
  select(city_state, results) %>% 
  unnest(results) %>% 
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(city_state, term, OR, starts_with("CI")) 
```

```{r}
models_results_df %>% 
  filter(term == "victim_sexMale") %>% 
  mutate(city_state = fct_reorder(city_state, OR)) %>% 
  ggplot(aes(x = city_state, y = OR)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper)) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```



## Problem 2

Find some residuals


Data looks pretty tidy already, don't think we need to do any cleaning up in this aspect. all variables are numeric as well. **do i need to change the 0/1 to the actaul names?**
```{r}
baby_df = 
  read_csv("./large_data/birthweight.csv")
```

fit a model

In order to insure that I am able to cross validate, the model i created are nested with the two models i will need to compare during a later stage of the homework.  in addition to these 4 required variables, i added one more additional variable, `momage` to see how that predictor influences the outcome.  


```{r}
model = lm(bwt~ blength + bhead + babysex + gaweeks + momage, data = baby_df)
```

```{r}
model %>%  broom::tidy() %>% 
  knitr::kable(digits = 3)
```

**make a plot**

show a plot of model residuals against fitted values – use add_predictions and add_residuals in making this plot.
```{r}
baby_df %>% 
  modelr::add_residuals(model) %>% 
  ggplot(aes(x = momage, y = resid)) + 
  geom_point()
```

is there any skewness? yes, this is right skewed
any trend, something that is nonlinear? no distinct trends appear
any extreme outliers. can be observed around the age 20.  There appears to be 3 values that are above 1500 for residual values. 

```{r}
fit_1 = lm(bwt ~ blength + gaweeks, data = baby_df)
fit_2 = lm(bwt ~ bhead*blength + babysex*bhead + babysex*blength + babysex*bhead*blength, data = baby_df)
```

The first model that we need to compare
```{r}
fit_1 %>% 
   broom::tidy() %>% 
  knitr::kable(digits = 3)
```

let's look at the second model we need to compare
```{r}
fit_2 %>% 
   broom::tidy() %>% 
  knitr::kable(digits = 3)
```


Cross validation babes
```{r}
baby_cv = 
  crossv_mc(baby_df, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble),
    crude = map(.x = train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    full = map(.x = train, ~lm(bwt ~ bhead*blength + babysex*bhead +  
                                 babysex*blength + babysex*bhead*blength, 
                                data = baby_df)), 
    rmse_crude = map2_dbl(.x = crude, .y = test, ~rmse(model = .x, data = .y)),
    rmse_full = map2_dbl(.x = full, .y = test, ~rmse(model = .x, data = .y))
  )

```

### Problem 3
load data
```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

```{r}
#create a dataset of 5000 rows
n_samp = 5000

sim_df_const = 
  tibble(
    x = rnorm(n_samp, 1, 1),
    error = rnorm(n_samp, 0, 1),
    y = 2 + 3 * x + error
  )

sim_df_nonconst = sim_df_const %>% 
  mutate(
  error = error * .75 * x,
  y = 2 + 3 * x + error
)

sim_df = 
  bind_rows(const = sim_df_const, nonconst = sim_df_nonconst, .id = "weather_df") 
```

Preparation of the data frame for the first component of the problem

```{r}
boot_df = 
weather_df %>% 
  modelr::bootstrap(n = 5000) %>% 
  mutate(
    models = map(strap, ~lm(tmax~tmin, data = .x)),
    results = map(models, broom::glance)
  ) %>% 
  select(results, .id) %>% 
  unnest(results)
  
```

We can observe from the r-squared plot that the distribution is relatively normal.  There is a slight skew towards the right where the values are closer to 1.
```{r}
r2_plot = 
  boot_df %>% 
  ggplot(aes(x = r.squared)) + geom_density()

r2_plot  
```


Preparation of the data frame for the next component of the problem
```{r}
beta_df = 
weather_df %>% 
  modelr::bootstrap(n = 5000) %>% 
  mutate(
    models = map(strap, ~lm(tmax~tmin, data = .x)),
    results = map(models, broom::tidy)
  ) %>% 
  select(results, .id) %>% 
  unnest(results) %>% 
  select(term, estimate) %>% 
  pivot_wider(
  names_from = "term", 
  values_from = "estimate") %>% 
  janitor::clean_names() %>% 
  unnest(tmin, intercept)


```

We can observe from the log(β̂0∗β1) plot that the distribution is relatively normal.  
```{r}
beta_plot = 
  beta_df %>% 
  ggplot(aes(x = log(intercept*tmin))) + geom_density()
 
beta_plot 
```

 
 The 95% confidence interval created via the 2.5% and 97.5% quantiles for r squared is as follows
```{r}
 
  quantile(boot_df$r.squared, 0.025)
  quantile(boot_df$r.squared, .975) 
 
```
 
 Created a new column to consider log(β̂0∗β1)
```{r}
beta_df =
  beta_df %>% 
  mutate(
    newvalue = log(intercept*tmin)
  )
```

 The 95% confidence interval created via the 2.5% and 97.5% quantiles for log(β̂0∗β1 is as follows
```{r}

  quantile(beta_df$newvalue, 0.025)
  quantile(beta_df$newvalue, .975) 
```




