---
title: "p8105_HW6_rkm2147"
author: "Ronae McLin"
date: "12/7/2020"
output: github_document
---


```{r setup, include=FALSE}
library(tidyverse)
library(viridis)
knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

```{r load_libraries}
library(tidyverse)
library(modelr)
library(p8105.datasets)
library(mgcv)
```

### Problem 1

```{r}
homicide_df = 
  read_csv("./large_data/homicide-data.csv", na = c("", "NA", "Unknown")) %>% 
  mutate(
    city_state = str_c(city, state, sep = ", "),
    victim_age = as.numeric(victim_age),
    resolution = case_when(
      disposition == "Closed without arrest" ~ 0,
      disposition == "Open/No arrest"        ~ 0,
      disposition == "Closed by arrest"      ~ 1)
  ) %>% 
  filter(
    victim_race %in% c("White", "Black"),
    city_state != "Tulsa, AL") %>% 
  select(city_state, resolution, victim_age, victim_race, victim_sex)
```


Start with one city.

```{r}
baltimore_df =
  homicide_df %>% 
  filter(city_state == "Baltimore, MD")
glm(resolution ~ victim_age + victim_race + victim_sex, 
    data = baltimore_df,
    family = binomial()) %>% 
  broom::tidy() %>% 
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(term, OR, starts_with("CI")) %>% 
  knitr::kable(digits = 3)
```


Try this across cities.

```{r}
models_results_df = 
  homicide_df %>% 
  nest(data = -city_state) %>% 
  mutate(
    models = 
      map(.x = data, ~glm(resolution ~ victim_age + victim_race + victim_sex, data = .x, family = binomial())),
    results = map(models, broom::tidy)
  ) %>% 
  select(city_state, results) %>% 
  unnest(results) %>% 
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(city_state, term, OR, starts_with("CI")) 
```

```{r}
models_results_df %>% 
  filter(term == "victim_sexMale") %>% 
  mutate(city_state = fct_reorder(city_state, OR)) %>% 
  ggplot(aes(x = city_state, y = OR)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper)) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```



## Problem 2


### load data and tidy
 
```{r}
baby_df = 
  read_csv("./large_data/birthweight.csv")
```

tidy baby data frame, names were placed for the numeric values
```{r}
baby_df = 
  baby_df %>% 
  mutate(
    babysex = case_when(
      babysex == "1" ~ "male",
      babysex == "2" ~ "female"
    ),
    
    frace = case_when(
      frace == "1" ~ "white", 
      frace == "2" ~ "black",
      frace == "3" ~ "asian", 
      frace == "4" ~ "puerto rican",
      frace == "8" ~ "other", 
      frace == "9" ~ "unknown"
      
      ),
    
    malform = case_when(
      malform == "0" ~ "absent",
      malform == "1" ~ "present" 
    ),
    
    mrace = case_when(
      mrace == "1" ~ "white", 
      mrace == "2" ~ "black",
      mrace == "3" ~ "asian", 
      mrace == "4" ~ "puerto rican",
      mrace == "8" ~ "other" 
  ))
```


In order to insure that I am able to cross validate, the model i created are nested with the two models i will need to compare during a later stage of the homework.  in addition to these 4 required variables, i added one more additional variable, `momage` to see how that predictor influences the outcome.  

```{r}
#model1 on the plot
my_model = lm(bwt~ blength + bhead + babysex + gaweeks + momage, data = baby_df)

#model2 and model3 respectively
fit_1 = lm(bwt ~ blength + gaweeks, data = baby_df)
fit_2 = lm(bwt ~ bhead*blength + babysex*bhead + babysex*blength + babysex*bhead*blength, data = baby_df)
```


### Create a model and plot it!

We can observe from this plot that it is left skewed, with values clustering between 2000-4000 (for predictions). No distinct trends appear from this plot. Extreme outliers can be observed around prediction value of 1000 and below. Also this can observed for residuals greater than 1000.  There appears to be 3 values that are above 1500 for residual values. 
```{r}
residual_plot = 
baby_df %>% 
  modelr::add_residuals(my_model) %>% 
  add_predictions(my_model) %>%  
  ggplot(aes(x = pred, y = resid)) + 
  geom_point() +
  labs(
    title = "plot of my proposed model's residuals against fitted values",
    x = "Predictions",
    y = "Residuals"
  )

residual_plot
```

### tidy table of the created models 
```{r}
#this is model1 on the plot
my_model %>% 
   broom::tidy() %>% 
  knitr::kable(digits = 3)

```

let's look at the first model we need to compare
```{r}
#this is model2 on the plot
fit_1 %>% 
   broom::tidy() %>% 
  knitr::kable(digits = 3)
```

let's look at the second model we need to compare
```{r}
# this is model3 on the plot
fit_2 %>% 
   broom::tidy() %>% 
  knitr::kable(digits = 3)
```

### Cross validation

```{r}
cv_df = 
  crossv_mc(baby_df, 100) 
```

```{r}
cv_df =
  cv_df %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))
```


Cross validation occurs
```{r}
cv_df =
  cv_df %>% 
  mutate(
    model_1 = map(.x = train, ~lm(bwt ~ blength + bhead + babysex + gaweeks +                                   momage, data = .x)),
    model_2 = map(.x = train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    model_3 = map(.x = train, ~lm(bwt ~ bhead*blength + babysex*bhead +  
                                 babysex*blength + babysex*bhead*blength, 
                                data = .x)),
     rmse_model1 = map2_dbl(.x = model_1, .y = test, ~rmse(model = .x, data = .y)),
    rmse_model2 = map2_dbl(.x = model_2, .y = test, ~rmse(model = .x, data = .y)),
    rmse_model3 = map2_dbl(.x = model_3, .y = test, ~rmse(model = .x, data = .y)))
  

```

We can observe that my proposed model (model1 on the plot) is more parsimonious with model 3 than with model2. The two models are relatively similar except for the `momage` variable, so this makes sense. 
```{r}
validation_plot = 
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin() +
  labs(
    title = "plot of my proposed model vs the model2 and model3",
    x = "rmse",
    y = "Model"
  )

validation_plot
```

### Problem 3
load data
```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

```{r}
#pulled from p8105 lecture as a guidance
n_samp = 5000

sim_df_const = 
  tibble(
    x = rnorm(n_samp, 1, 1),
    error = rnorm(n_samp, 0, 1),
    y = 2 + 3 * x + error
  )

sim_df_nonconst = sim_df_const %>% 
  mutate(
  error = error * .75 * x,
  y = 2 + 3 * x + error
)

sim_df = 
  bind_rows(const = sim_df_const, nonconst = sim_df_nonconst, .id = "weather_df") 
```

Preparation of the data frame for the first component of the problem

```{r}
boot_df = 
weather_df %>% 
  modelr::bootstrap(n = 5000) %>% 
  mutate(
    models = map(strap, ~lm(tmax~tmin, data = .x)),
    results = map(models, broom::glance)
  ) %>% 
  select(results, .id) %>% 
  unnest(results)
  
```

We can observe from the r-squared plot that the distribution is relatively normal.  There is a slight left skew, towards where the values are closer to 1.
```{r}
r2_plot = 
  boot_df %>% 
  ggplot(aes(x = r.squared)) + geom_density() +
  labs(
    title = "Distribution of r.squared estimates",
    x = "r.squared",
    y = "density"
  )


r2_plot  
```


Preparation of the data frame for the next component of the problem
```{r}
beta_df = 
weather_df %>% 
  modelr::bootstrap(n = 5000) %>% 
  mutate(
    models = map(strap, ~lm(tmax~tmin, data = .x)),
    results = map(models, broom::tidy)
  ) %>% 
  select(results, .id) %>% 
  unnest(results) %>% 
  select(term, estimate) %>% 
  pivot_wider(
  names_from = "term", 
  values_from = "estimate") %>% 
  janitor::clean_names() %>% 
  unnest(tmin, intercept) %>% 
mutate(
    newvalue = log(intercept*tmin)
  )

```

We can observe from the log(β̂0∗β1) plot that the distribution is relatively normal.  
```{r}
beta_plot = 
  beta_df %>% 
  ggplot(aes(x = log(intercept*tmin))) + geom_density() +
  labs(
    title = "Distribution of log(β̂0∗β1) estimates",
    x = "log(β̂0∗β1",
    y = "density"
  )
 
beta_plot 
```

 
 The 95% confidence interval created via the 2.5% and 97.5% quantiles for r squared is as follows
```{r}
 
  quantile(boot_df$r.squared, 0.025)
  quantile(boot_df$r.squared, .975) 
 
```
 

 The 95% confidence interval created via the 2.5% and 97.5% quantiles for log(β̂0∗β1 is as follows
```{r}

  quantile(beta_df$newvalue, 0.025)
  quantile(beta_df$newvalue, .975) 
```




